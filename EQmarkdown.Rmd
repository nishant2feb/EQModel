---
title: "Earthquake Sample Model"
author: "Nishant"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Sample Data Collection Details
The sample data is taken by randomly selecting the region of south east asia covering the countries `Malaysia`, `Indomesia` etc..
The sample data taken over a period of one year from **10 Feb 2017** to **10 Feb 2018**.
The data model used here may or may not be used in final model as it all depends on the structure and 

```{r libraries, message=FALSE, warning=FALSE, echo=FALSE}
library(caret)
library(ggplot2)
library(dplyr)
library(lubridate)
library(PerformanceAnalytics)

```

## Data Overview
We will overview our data and remove unwanted or low variance features.
```{r Cleaning data, echo=FALSE}
#importing data

DataEq = read.csv("oneyear.csv", stringsAsFactors = FALSE)

summary(DataEq)

#removing NA columns

DataEq = DataEq[ , -7]

class(DataEq$time)

#converting time to usable format

DataEq$time = ymd_hms(as_datetime(DataEq$time))
DataEq$updated = ymd_hms(as_datetime(DataEq$updated))
DataEq$year = year(DataEq$time)
DataEq$month = month(DataEq$time)
DataEq$day = day(DataEq$time)

#pattern in width and magnitude of the earthquake

ggplot(DataEq, aes(x = mag, y = depth, col = magType))+
  geom_point(alpha = 0.6)+
  facet_wrap(~ month)+
  theme_light()

# Removing no variance data

eqClean = DataEq[ , c(-10, -11, -14, -19, -20,-21)]

```

## Correlation of numeric Data
We observe the correlation of numeric data.

```{r Correlation plot, message=FALSE, warning=FALSE}

numClean = eqClean[, c(-1, -6, -10, -11)]

chart.Correlation(numClean)

```

## Some random plots 
Lets plot some random scatter plots with some fetaure engineering for better understanding of the for now I will go with latitude and longitude and see the behaviour.Some feature engineering is encorporated but it soes not change the characterstics of the plot.

>  *Note: In every plot some changes applied on one of the plotted variable but it does not change the behaviour.* 

```{r Scatterplot of faultline, message=FALSE, warning=FALSE, echo=FALSE}
#scatterplot of lan and lat

ggplot(eqClean, aes(x = latitude, y = longitude, col = factor(mag))) +
  geom_point(alpha = 0.4)+
  facet_wrap(~ month)+
  theme_classic()

summary(eqClean$latitude)

eqClean$latCre = eqClean$latitude + 11.7622
summary(eqClean$latCre)

ggplot(eqClean, aes(x = latCre, y = longitude, col = factor(mag))) +
  geom_point(alpha = 0.4)+
  facet_wrap(~ month)+
  theme_classic()

eqClean$longCre = sqrt(eqClean$longitude)

ggplot(eqClean, aes(x = latCre, y = longCre, col = factor(mag))) +
  geom_point(alpha = 0.4)+
  facet_wrap(~ month)+
  theme_classic()

eqClean$Constant = eqClean$latCre * eqClean$longitude
summary(eqClean$Constant)

ggplot(eqClean, aes(x = Constant, y = longitude, col = factor(mag))) +
  geom_point(alpha = 0.4)+
  facet_wrap(~ month)+
  theme_classic()
```

## Fitting Data in SVR(Support Vector Regression)
From the plots we can visualise the fault line and clearly see the occurences of earthquakes in the region, the fiiting is to find the line with higest risk.

```{r, message=FALSE, warning=FALSE}
#data for svr
dataset_all = eqClean[ , c(2, 3, 4, 5, 17)]
dataset = dataset_all[ , c(1, 2)]

#fitting the fault Line

library(e1071)
regressor = svm(formula = latitude ~ .,
                data = dataset,
                type = 'eps-regression',
                kernel = 'radial')

summary(regressor)
names(regressor)

y_pred = predict(regressor, newdata = dataset)

# plotting real and predicted

ggplot() +
  geom_point(aes(x = dataset$longitude, y = dataset$latitude),
             colour = 'red') +
  geom_line(aes(x = dataset$longitude, y = predict(regressor, newdata = dataset)),
            colour = 'blue') +
  ggtitle('fitting fault line') +
  xlab('longitude') +
  ylab('lattitude')
```

The curve fitted accurately upto a certain point. In the plot we can see requirement of two models.

### Dividing the data in two subsets 
The dataset will be divided into two subsets, the point is taken from where the model does not fit.

```{r, message=FALSE, warning=FALSE}

# dividing the data to have a better view of the fault line

lon_indx = which(dataset$longitude <= 120)
dataset_cut = dataset[lon_indx, ]

#looking into second index of the data

dataset_cut1 = dataset[-lon_indx, ]

```


## Fitting data in First Dataset
The data now fitted more accurately few data points are again observed deviating the curve, right now the points will be considered for better understanding over large dataset. 

```{r, message=FALSE, warning=FALSE}

#Plotting the cut dataset

ggplot() +
  geom_point(aes(x = dataset_cut$longitude, y = dataset_cut$latitude),
             colour = 'red') +
  geom_line(aes(x = dataset_cut$longitude, y = predict(regressor, newdata = dataset_cut)),
            colour = 'blue') +
  ggtitle('fitting fault line') +
  xlab('longitude') +
  ylab('lattitude')

```

## Fitting data in Second Dataset
The data forming clusters on first look it feels to form 5 clusters so we tend to use kmean to cluster the data and identify the centers of the cluster 

```{r, message=FALSE, warning=FALSE}

#looking into second index of the data

ggplot(dataset_cut1, aes(x = latitude, y = longitude)) +
  geom_point(alpha = 0.4)

#applying cluster analysis

kmeanCluster = kmeans(dataset_cut1, centers = 5, nstart = 30)
summary(kmeanCluster)

#centers of the cluster

clusterCenters = data.frame(kmeanCluster$centers)

#plotting the cluster

ggplot(dataset_cut1, aes(x = latitude, y = longitude)) +
         geom_point(aes(col = factor(kmeanCluster$cluster)))

clusterCenters

```

Through these two models we can estimate a point with maximum risk and through the variance between the input and high risk points we can categorise the zone.

**  The model is further enhanced by encorporating few more models and ideas like the latest earthquake centers or the model dveloped by you. **

## Data Exploration For Magnitude and Month
The data volume is not giving a clear picture into the relation.
I kept the scenario for further analysis and work on larger data chunk to generate a probability between earthquake occurences and time.

```{r, message=FALSE, warning=FALSE}

magClean = eqClean[, c(5, 17, 18)]
magClean = magClean%>%
  mutate(mgIntensity = ifelse(magClean$mag < 4, "low", 
                              ifelse(magClean$mag <= 5.5, "medium", "high")))

indx_high = which(magClean$mgIntensity == "high")
indx_medium = which(magClean$mgIntensity == "medium")
summary(magClean[indx_high, ])
summary(magClean[indx_medium, ])

summ_month_mag = magClean %>%
  group_by(month, mgIntensity, day)%>%
  summarise(no = n())


ggplot(summ_month_mag, aes(x = month, fill = mgIntensity))+
  geom_histogram(bins = 12, binwidth =  1)+
  scale_x_continuous()+
  scale_y_continuous()+
  theme_classic()

```

